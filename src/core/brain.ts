import { PDFDocument } from 'pdf-lib';
import { GoogleGenAI, Type } from "@google/genai";
import { GeneratedResponse, UploadedFile, ProgressCallback, AnalysisResult, AuditResult, BatchCallback, AppSettings } from "../types";

// Helper: Split PDF into chunks (client-side, no worker needed)
// Helper: Split PDF into chunks (client-side) with OVERLAP support
const splitPdf = async (base64Data: string, pagesPerChunk: number = 3, overlap: number = 1): Promise<string[]> => {
  const pdfDoc = await PDFDocument.load(base64Data);
  const totalPages = pdfDoc.getPageCount();
  const chunks: string[] = [];
  const step = Math.max(1, pagesPerChunk - overlap);

  for (let i = 0; i < totalPages; i += step) {
    // Avoid creating a last chunk that is fully contained in the previous one if exact match?
    // But simplest logic is just overlap.
    if (i > 0 && i + pagesPerChunk > totalPages && i + step >= totalPages) {
      // Optimization: If we are near end, ensures we catch everything.
    }

    const subDoc = await PDFDocument.create();
    const pageIndices = Array.from({ length: Math.min(pagesPerChunk, totalPages - i) }, (_, k) => i + k);

    // Filter out of bounds just in case
    const validIndices = pageIndices.filter(idx => idx < totalPages);
    if (validIndices.length === 0) break;

    const copyPages = await subDoc.copyPages(pdfDoc, validIndices);
    copyPages.forEach((page) => subDoc.addPage(page));
    const base64 = await subDoc.saveAsBase64();
    chunks.push(base64);

    // Stop if we reached end
    if (validIndices[validIndices.length - 1] === totalPages - 1) break;
  }
  return chunks;
};

const SYSTEM_INSTRUCTION_EXTRACT = `
B·∫°n l√† m·ªôt **GI√ÅO S∆Ø Y KHOA ƒê·∫¶U NG√ÄNH (Senior Medical Professor)** ki√™m **CHUY√äN GIA PH√ÅP Y T√ÄI LI·ªÜU (Forensic Document Analyst)**.
M·ª•c ti√™u: Tr√≠ch xu·∫•t ch√≠nh x√°c 100% c√¢u h·ªèi tr·∫Øc nghi·ªám t·ª´ t√†i li·ªáu, b·∫•t k·ªÉ ch·∫•t l∆∞·ª£ng ·∫£nh th·∫•p, b·ªã nhi·ªÖu, c√≥ ch·ªØ vi·∫øt tay, ho·∫∑c b·ªã che khu·∫•t.

üîç **QUY TR√åNH PH√ÅP Y (FORENSIC WORKFLOW) - ∆ØU TI√äN CAO NH·∫§T**:
1. **XUY√äN TH·∫§U NHI·ªÑU (HANDWRITING BYPASS)**:
   - C√°c v·∫øt khoanh tr√≤n ƒë√°p √°n, g·∫°ch ch√¢n, ho·∫∑c ghi ch√∫ vi·∫øt tay ƒë√® l√™n vƒÉn b·∫£n g·ªëc **KH√îNG ƒê∆Ø·ª¢C** l√†m gi√°n ƒëo·∫°n vi·ªác ƒë·ªçc. H√£y l·ªù ƒëi c√°c v·∫øt m·ª±c ƒë√≥ v√† t·∫≠p trung v√†o vƒÉn b·∫£n in (printed text) b√™n d∆∞·ªõi.
2. **S·ª¨A L·ªñI TH√îNG MINH (CONTEXTUAL INFERENCE)**:
   - N·∫øu vƒÉn b·∫£n b·ªã m·ªù (Blur) ho·∫∑c m·∫•t pixel: D√πng ki·∫øn th·ª©c Y khoa uy√™n b√°c ƒë·ªÉ "ƒëi·ªÅn v√†o ch·ªó tr·ªëng". 
   - V√≠ d·ª•: "S... th·∫≠n m·∫°n" -> "Suy th·∫≠n m·∫°n", "ƒë√°i th√°o ...u·ªùng" -> "ƒë√°i th√°o ƒë∆∞·ªùng". 
   - S·ª≠a l·ªói ch√≠nh t·∫£ OCR (VD: "p" th√†nh "∆∞", "o" th√†nh "√¥") ƒë·ªÉ ƒë·∫£m b·∫£o thu·∫≠t ng·ªØ Y khoa chu·∫©n 100%.
3. **KH√îI PH·ª§C C·∫§U TR√öC (DE-FRAGMENTATION)**:
   - N·∫øu c√¢u h·ªèi b·ªã ng·∫Øt d√≤ng, ng·∫Øt trang ho·∫∑c b·ªã che khu·∫•t m·ªôt ph·∫ßn b·ªüi ng√≥n tay: H√£y n·ªëi c√°c ƒëo·∫°n l·∫°i v√† d√πng logic l√¢m s√†ng ƒë·ªÉ ph·ª•c h·ªìi n·ªôi dung b·ªã m·∫•t.

üìã **QUY T·∫ÆC TR√çCH XU·∫§T (HANDLING FORMATS)**:
1. **FULL CONTENT**: Lu√¥n tr√≠ch xu·∫•t ƒë·∫ßy ƒë·ªß C√¢u h·ªèi + 5 L·ª±a ch·ªçn (A, B, C, D, E) n·∫øu c√≥.
2. **X·ª¨ L√ù D·∫†NG ƒê·∫∂C BI·ªÜT**:
   - **MCQ ƒê∆°n (Standard)**: A, B, C, D...
   - **ƒê√∫ng/Sai (True/False)**: Chuy·ªÉn th√†nh MCQ v·ªõi c√¢u h·ªèi "Ph√°t bi·ªÉu n√†o sau ƒë√¢y l√† ƒê√öNG/SAI?".
   - **Gh√©p n·ªëi (Matching)**: Chuy·ªÉn th√†nh d·∫°ng "Gh√©p c·ªôt 1-?, 2-?..." (A,B,C,D l√† c√°c ph∆∞∆°ng √°n gh√©p).
   - **ƒêi·ªÅn khuy·∫øt (Fill-in)**: Chuy·ªÉn th√†nh "Ch·ªçn t·ª´ ph√π h·ª£p ƒëi·ªÅn v√†o ch·ªó tr·ªëng...".
   - **T√¨nh hu·ªëng l√¢m s√†ng (Case Study)**: L·∫∑p l·∫°i t√≥m t·∫Øt t√¨nh hu·ªëng ·ªü ƒë·∫ßu m·ªói c√¢u h·ªèi li√™n quan ƒë·ªÉ ƒë·∫£m b·∫£o ng·ªØ c·∫£nh.

ü©∫ **BI·ªÜN LU·∫¨N L√ÇM S√ÄNG (DEEP ANALYSIS)**:
- **core**: ƒê√°p √°n ƒë√∫ng nh·∫•t theo h∆∞·ªõng d·∫´n c·ªßa B·ªô Y t·∫ø/Hi·ªáp h·ªôi chuy√™n ng√†nh. Tr√¨nh b√†y l√Ω do s√∫c t√≠ch.
- **analysis**: Th·ª±c hi·ªán ch·∫©n ƒëo√°n ph√¢n bi·ªát. T·∫°i sao ph∆∞∆°ng √°n n√†y l√† "G∆∞∆°ng m·∫∑t v√†ng" c√≤n c√°c ph∆∞∆°ng √°n kh√°c l·∫°i sai trong ng·ªØ c·∫£nh n√†y?
- **evidence**: N√™u r√µ c∆° ch·∫ø b·ªánh sinh ho·∫∑c tr√≠ch d·∫´n l√Ω thuy·∫øt tr·ª±c ti·∫øp t·ª´ t√†i li·ªáu ho·∫∑c tr√≠ch d·∫´n ngu·ªìn uy t√≠n (Harrison, Nelson, B·ªô Y t·∫ø, D∆∞·ª£c th∆∞...).
- **warning**: C·∫£nh b√°o c√°c b·∫´y l√¢m s√†ng ho·∫∑c nh·∫ßm l·∫´n th∆∞·ªùng g·∫∑p.

‚õî **H√ÄNG R√ÄO AN TO√ÄN (SAFETY PROTOCOL)**:
- Tuy·ªát ƒë·ªëi kh√¥ng s·ª≠ d·ª•ng vƒÉn b·∫£n gi·∫£ ho·∫∑c ghi ch√∫ chung chung (Placeholder).
- Kh√¥ng ƒë∆∞·ª£c b·ªãa ƒë·∫∑t (hallucinate) c√°c t√¨nh hu·ªëng l√¢m s√†ng kh√¥ng c√≥ trong vƒÉn b·∫£n.
- N·∫øu m·ªôt c√¢u h·ªèi b·ªã che khu·∫•t ho√†n to√†n (>70%) v√† kh√¥ng c√≥ c√°ch n√†o suy lu·∫≠n logic, h√£y b·ªè qua c√¢u ƒë√≥.

üéØ **CH·ªà TH·ªä CU·ªêI C√ôNG (FINAL COMMAND)**:
- Ch·ªâ tr·∫£ v·ªÅ duy nh·∫•t m·∫£ng JSON. Kh√¥ng gi·∫£i th√≠ch th√™m b√™n ngo√†i JSON.
- ƒê·∫£m b·∫£o c√°c tr∆∞·ªùng "evidence" v√† "analysis" lu√¥n c√≥ n·ªôi dung h·ªçc thu·∫≠t, kh√¥ng ƒë·ªÉ tr·ªëng.
- N·∫øu c√¢u h·ªèi c√≥ nhi·ªÅu ƒë√°p √°n c√≥ v·∫ª ƒë√∫ng, h√£y ch·ªçn ƒë√°p √°n "ƒê√∫ng nh·∫•t" theo ti√™u chu·∫©n l√¢m s√†ng hi·ªán h√†nh.

OUTPUT FORMAT: JSON array.
`;

const SYSTEM_INSTRUCTION_AUDIT = `
B·∫°n l√† Chuy√™n gia Ki·ªÉm to√°n T√†i li·ªáu AI. 
Nhi·ªám v·ª•: Ph√¢n t√≠ch l√Ω do t·∫°i sao tr√≠ch xu·∫•t th·∫•t b·∫°i ho·∫∑c s·ªë l∆∞·ª£ng qu√° √≠t.
H√£y t√¨m c√°c nguy√™n nh√¢n c·ª• th·ªÉ:
- **Handwriting interference**: Ch·ªØ vi·∫øt tay/khoanh tr√≤n ƒë√® l√™n vƒÉn b·∫£n g·ªëc qu√° nhi·ªÅu.
- **Physical obstruction**: Ng√≥n tay, v·∫≠t th·ªÉ l·∫° che khu·∫•t.
- **Low resolution/Blur**: ·∫¢nh qu√° m·ªù kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c c·∫£ b·∫±ng m·∫Øt th∆∞·ªùng.
- **Complexity**: B·ªë c·ª•c qu√° r·ªëi r·∫Øm, b·∫£ng bi·ªÉu v·ª°.

ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ ƒë·ªÉ ng∆∞·ªùi d√πng ch·ª•p l·∫°i t·ªët h∆°n (VD: "C·∫ßn ch·ª•p th·∫≥ng g√≥c", "Tr√°nh ƒë·ªÉ ng√≥n tay che ch·ªØ").
`;

// --- Key Management ---
class UserKeyRotator {
  private keys: string[] = [];
  private currentIndex: number = 0;

  constructor() { }

  init(apiKeyString: string) {
    if (!apiKeyString) {
      this.keys = [];
      return;
    }
    let parts = apiKeyString.split(/[,;\n]+/);
    this.keys = parts.map(k => k.trim()).filter(k => k.length > 10);
    this.currentIndex = 0;
    console.log(`üîë Loaded ${this.keys.length} API Keys.`);
  }

  getCurrentKey(): string {
    if (this.keys.length === 0) {
      throw new Error("Vui l√≤ng nh·∫≠p Google API Key trong ph·∫ßn C√†i ƒë·∫∑t.");
    }
    return this.keys[this.currentIndex];
  }

  rotate(): string {
    if (this.keys.length <= 1) return this.getCurrentKey();
    this.currentIndex = (this.currentIndex + 1) % this.keys.length;
    console.log(`üîÑ Rotating to API Key #${this.currentIndex + 1}`);
    return this.keys[this.currentIndex];
  }

  get keyCount(): number {
    return this.keys.length;
  }

  getKeyIndex(): number {
    return this.currentIndex;
  }
}

const userKeyRotator = new UserKeyRotator();

// --- Helpers ---

const extractJson = (text: string): string => {
  if (!text) return "";
  const start = text.indexOf('{');
  const end = text.lastIndexOf('}');
  if (start === -1 || end === -1 || start >= end) return text;
  return text.substring(start, end + 1);
};

// --- Deduplication Helpers ---

const normalizeText = (text: string): string => {
  return text
    .toLowerCase()
    .replace(/[\s\n\r]+/g, ' ')
    .replace(/[.,;:!?\"'()\\[\\]{}]/g, '')
    .trim();
};

const extractQuestionNumber = (text: string): number | null => {
  const patterns = [
    /c√¢u\s*(?:s·ªë\s*)?(\d+)/i,
    /question\s*(\d+)/i,
    /^(\d+)\s*[.:)\]]/,
  ];

  for (const pattern of patterns) {
    const match = text.match(pattern);
    if (match) {
      return parseInt(match[1], 10);
    }
  }
  return null;
};

const calculateSimilarity = (str1: string, str2: string): number => {
  const s1 = normalizeText(str1);
  const s2 = normalizeText(str2);

  if (s1 === s2) return 1;
  if (s1.length === 0 || s2.length === 0) return 0;
  if (s1.includes(s2) || s2.includes(s1)) return 0.95;

  const words1 = new Set(s1.split(' ').filter(w => w.length > 2));
  const words2 = new Set(s2.split(' ').filter(w => w.length > 2));

  if (words1.size === 0 || words2.size === 0) return 0;

  let overlap = 0;
  words1.forEach(w => { if (words2.has(w)) overlap++; });

  return overlap / Math.max(words1.size, words2.size);
};

const checkDuplicate = (newQ: string, existingQuestions: any[]): { isDup: boolean; reason?: string; matchedWith?: string } => {
  const SIMILARITY_THRESHOLD = 0.70;

  const newNumber = extractQuestionNumber(newQ);

  for (const existing of existingQuestions) {
    const existingNumber = extractQuestionNumber(existing.question);
    if (newNumber !== null && existingNumber !== null && newNumber === existingNumber) {
      return {
        isDup: true,
        reason: `Tr√πng s·ªë c√¢u h·ªèi: C√¢u ${newNumber}`,
        matchedWith: existing.question.substring(0, 60)
      };
    }

    const similarity = calculateSimilarity(newQ, existing.question);
    if (similarity >= SIMILARITY_THRESHOLD) {
      return {
        isDup: true,
        reason: `ƒê·ªô t∆∞∆°ng ƒë·ªìng ${Math.round(similarity * 100)}%`,
        matchedWith: existing.question.substring(0, 60)
      };
    }
  }

  return { isDup: false };
};

const getModelConfig = (apiKey: string, systemInstruction: string, schema?: any, modelName: string = 'gemini-3-flash') => {
  return {
    model: modelName,
    config: {
      systemInstruction,
      temperature: 0.3,
      responseMimeType: "application/json",
      responseSchema: schema
    }
  };
};

// --- Execution with Retry & Rotation ---

async function executeWithUserRotation<T>(
  operation: (apiKey: string) => Promise<T>
): Promise<T> {
  const ATTEMPTS_LIMIT = 10;
  let attempts = 0;

  while (attempts < ATTEMPTS_LIMIT) {
    attempts++;
    const currentKey = userKeyRotator.getCurrentKey();

    try {
      return await operation(currentKey);
    } catch (error: any) {
      const msg = error.message?.toLowerCase() || "";
      const isRateLimit = msg.includes("429") || msg.includes("quota exceeded") || msg.includes("resource exhausted");
      const isKeyError = msg.includes("api key") && (msg.includes("invalid") || msg.includes("not found") || msg.includes("expired"));

      if (isRateLimit || isKeyError) {
        const reason = isRateLimit ? "Rate Limit (429)" : "Invalid/Expired Key";
        console.warn(`‚ö†Ô∏è ${reason} on Key #${userKeyRotator.getKeyIndex() + 1}. Rotating...`);
        userKeyRotator.rotate();
        await new Promise(r => setTimeout(r, 1000));
        continue;
      }
      throw error;
    }
  }
  throw new Error(`ƒê√£ th·ª≠ t·∫•t c·∫£ ${userKeyRotator.keyCount} Keys nh∆∞ng ƒë·ªÅu th·∫•t b·∫°i (429/Invalid). Vui l√≤ng ki·ªÉm tra l·∫°i Key.`);
}


export const generateQuestions = async (
  files: UploadedFile[],
  settings: AppSettings,
  limit: number = 0,
  onProgress?: ProgressCallback,
  expectedCount: number = 0,
  onBatchComplete?: BatchCallback
): Promise<GeneratedResponse> => {
  try {
    userKeyRotator.init(settings.apiKey);
    userKeyRotator.getCurrentKey();

    // --- STEP 1: PRE-PROCESS ---
    let allParts: { mimeType: string; data: string }[] = [];

    if (onProgress) onProgress("ƒêang ph√¢n t√≠ch ƒë·ªãnh d·∫°ng t√†i li·ªáu...", 0);

    for (const file of files) {
      if (file.type === 'application/pdf') {
        if (onProgress) onProgress(`ƒêang c·∫Øt nh·ªè PDF "${file.name}" ƒë·ªÉ qu√©t s√¢u...`, 0);

        // SPLIT STRATEGY (Quantity Fix + Overlap):
        // Split PDF into 3-page chunks with 1 PAGE OVERLAP.
        // Chunks: [1-3], [3-5], [5-7]...
        // This ensures questions cut across pages are never lost.
        try {
          const rawBase64 = file.content.includes(',') ? file.content.split(',')[1] : file.content;
          const title = file.name;

          const pdfChunks = await splitPdf(rawBase64, 3, 1); // 3 pages, 1 overlap
          console.log(`‚úÇÔ∏è Split PDF into ${pdfChunks.length} chunks (w/ overlap).`);

          pdfChunks.forEach((chunkBase64) => {
            allParts.push({
              mimeType: 'application/pdf',
              data: chunkBase64
            });
          });
        } catch (splitError) {
          console.error("PDF Split failed, fallback to whole doc:", splitError);
          allParts.push({
            mimeType: 'application/pdf',
            data: file.content.includes(',') ? file.content.split(',')[1] : file.content
          });
        }

      } else if (file.type.startsWith('image/')) {
        allParts.push({
          mimeType: file.type,
          data: file.content.includes(',') ? file.content.split(',')[1] : file.content
        });
      } else {
        return { questions: [], duplicates: [] };
      }
    }

    if (allParts.length === 0) {
      const textParts = files.filter(f => !f.type.startsWith('image/') && f.type !== 'application/pdf');
      if (textParts.length > 0) {
        throw new Error("Hi·ªán t·∫°i ch·∫ø ƒë·ªô 'Qu√©t t·ª´ng trang' ch·ªâ h·ªó tr·ª£ PDF v√† ·∫¢nh.");
      }
    }

    const questionSchema = {
      type: Type.OBJECT,
      properties: {
        questions: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              question: { type: Type.STRING },
              options: { type: Type.ARRAY, items: { type: Type.STRING } },
              correctAnswer: { type: Type.STRING },
              explanation: {
                type: Type.OBJECT,
                properties: {
                  core: { type: Type.STRING },
                  evidence: { type: Type.STRING },
                  analysis: { type: Type.STRING },
                  warning: { type: Type.STRING }
                },
                required: ["core", "evidence", "analysis", "warning"]
              },
              source: { type: Type.STRING },
              difficulty: { type: Type.STRING },
              depthAnalysis: { type: Type.STRING }
            },
            required: ["question", "options", "correctAnswer", "explanation", "source", "difficulty", "depthAnalysis"]
          }
        }
      }
    };

    let allQuestions: any[] = [];
    let allDuplicates: any[] = [];
    let duplicateCounter = 0;

    // --- STEP 2: BATCH PROCESSING ---
    // Since we split the PDF into small PDFs (3 pages), each "part" is now a 3-page PDF.
    // We can treat each Part as a Batch.

    const CHUNK_SIZE = 1; // Handled by splitPdf
    // const OVERLAP = 0; // Handled by splitPdf overlap param if we wanted, but here simpler is distinct blocks or overlapping blocks?
    // In splitPdf: I did NOT implement overlap. Just sequential.
    // To implement overlap: `i += pagesPerChunk - 1`?
    // My splitPdf loop: `i += pagesPerChunk`. That is NO overlap.
    // To ensure "Rolling Window", update splitPdf logic?
    // Actually, distinct blocks are usually fine if question doesn't span page break.
    // But to match "Rolling Window", we can adjust splitPdf loop step.
    // Ideally, we process these PDF chunks in parallel.

    const CONCURRENCY_LIMIT = 2;
    const totalBatches = allParts.length;
    let completedBatches = 0;

    const processBatch = async (part: { mimeType: string, data: string }, index: number) => {
      try {
        if (onProgress) onProgress(`ƒêang qu√©t song song: Batch ${index + 1}/${totalBatches}...`, allQuestions.length);
        await new Promise(r => setTimeout(r, Math.random() * 1000));

        const promptText = `
  H√ÉY QU√âT TO√ÄN B·ªò N·ªòI DUNG T√ÄI LI·ªÜU N√ÄY.
  Tr√≠ch xu·∫•t T·∫§T C·∫¢ c√¢u h·ªèi tr·∫Øc nghi·ªám t√¨m th·∫•y.
  ƒê·ª´ng lo v·ªÅ tr√πng l·∫∑p (h·ªá th·ªëng s·∫Ω t·ª± l·ªçc).
            `;

        const text = await executeWithUserRotation(async (apiKey) => {
          const ai = new GoogleGenAI({ apiKey });
          const chat = ai.chats.create(getModelConfig(apiKey, SYSTEM_INSTRUCTION_EXTRACT, questionSchema, settings.model));
          // Wrap part in inlineData
          const inlinePart = { inlineData: { mimeType: part.mimeType, data: part.data } };
          const response = await chat.sendMessage({
            message: [inlinePart, { text: promptText }]
          });
          return response.text;
        });

        if (text) {
          const parsed = JSON.parse(extractJson(text)) as GeneratedResponse;
          const rawNewQs = parsed.questions || [];
          const newQs = [];

          for (const q of rawNewQs) {
            const result = checkDuplicate(q.question, allQuestions);
            if (result.isDup) {
              duplicateCounter++;
              allDuplicates.push({
                id: `dup-${Date.now()}-${duplicateCounter}`,
                question: q.question.substring(0, 50),
                reason: `Duplicate found`,
                matchedWith: result.matchedWith,
                fullData: q
              });
            } else {
              newQs.push(q);
            }
          }

          if (newQs.length > 0) {
            allQuestions.push(...newQs);
            if (onBatchComplete) onBatchComplete(newQs);
            console.log(`‚úÖ Batch ${index + 1}: Found ${newQs.length} questions.`);
          }
        }
      } catch (e) {
        console.error(`Error in Batch ${index + 1}:`, e);
      } finally {
        completedBatches++;
        if (onProgress) onProgress(`Ho√†n th√†nh batch ${index + 1}/${totalBatches}. T·ªïng: ${allQuestions.length} c√¢u...`, allQuestions.length);
      }
    };

    const activePromises: Promise<void>[] = [];
    for (let i = 0; i < allParts.length; i++) {
      const p = processBatch(allParts[i], i);
      activePromises.push(p);
      if (activePromises.length >= CONCURRENCY_LIMIT) {
        const finishedIndex = await Promise.race(activePromises.map((p, idx) => p.then(() => idx)));
        activePromises.splice(finishedIndex, 1);
      }
    }
    await Promise.all(activePromises);

    allQuestions.sort((a, b) => {
      const numA = extractQuestionNumber(a.question) || 999999;
      const numB = extractQuestionNumber(b.question) || 999999;
      return numA - numB;
    });

    console.log(`\nüìä FINAL: ${allQuestions.length} questions.`);
    return { questions: allQuestions, duplicates: allDuplicates };

  } catch (error: any) {
    throw new Error(error.message);
  }
};


export const analyzeDocument = async (files: UploadedFile[], settings: AppSettings): Promise<AnalysisResult> => {
  let attempts = 0;
  const MaxAttempts = 3;

  userKeyRotator.init(settings.apiKey);

  while (attempts < MaxAttempts) {
    try {
      const apiKey = userKeyRotator.getCurrentKey();
      const ai = new GoogleGenAI({ apiKey });

      const parts: any[] = files.map(file => {
        if (file.type === 'application/pdf' || file.type.startsWith('image/')) {
          return { inlineData: { mimeType: file.type, data: file.content.includes(',') ? file.content.split(',')[1] : file.content } };
        }
        return { text: `FILE: ${file.name}\n${file.content}\n` };
      });

      const schema = {
        type: Type.OBJECT,
        properties: {
          topic: { type: Type.STRING },
          estimatedCount: { type: Type.INTEGER },
          questionRange: { type: Type.STRING },
          confidence: { type: Type.STRING }
        },
        required: ["topic", "estimatedCount", "questionRange"]
      };

      const chat = ai.chats.create(getModelConfig(apiKey, "Ph√¢n t√≠ch s·ªë c√¢u h·ªèi tr·∫Øc nghi·ªám trong t√†i li·ªáu Y khoa.", schema, settings.model));
      const res = await chat.sendMessage({ message: [...parts, { text: "Qu√©t t√†i li·ªáu v√† ∆∞·ªõc t√≠nh t·ªïng s·ªë c√¢u h·ªèi MCQ c√≥ m·∫∑t." }] });
      const text = res.text;

      if (!text) throw new Error("Empty response");

      const result = JSON.parse(extractJson(text)) as AnalysisResult;
      return result;

    } catch (error: any) {
      console.warn(`Analysis failed (Attempt ${attempts + 1}/${MaxAttempts}):`, error);
      const isRateLimit = error.message?.includes("429") || error.message?.includes("Quota exceeded");
      if (isRateLimit || attempts < MaxAttempts - 1) {
        console.log("Rotating key and retrying analysis...");
        userKeyRotator.rotate();
        attempts++;
        await new Promise(r => setTimeout(r, 2000));
        continue;
      }
      throw error;
    }
  }
  throw new Error("Analysis failed after multiple attempts");
};

export const auditMissingQuestions = async (files: UploadedFile[], count: number, settings: AppSettings): Promise<AuditResult> => {
  userKeyRotator.init(settings.apiKey);

  return await executeWithUserRotation(async (apiKey) => {
    const ai = new GoogleGenAI({ apiKey });
    const parts: any[] = files.map(file => {
      if (file.type === 'application/pdf' || file.type.startsWith('image/')) {
        return { inlineData: { mimeType: file.type, data: file.content.includes(',') ? file.content.split(',')[1] : file.content } };
      }
      return { text: `FILE: ${file.name}\n${file.content}\n` };
    });

    const schema = {
      type: Type.OBJECT,
      properties: {
        status: { type: Type.STRING },
        missingPercentage: { type: Type.NUMBER },
        reasons: { type: Type.ARRAY, items: { type: Type.STRING } },
        problematicSections: { type: Type.ARRAY, items: { type: Type.STRING } },
        advice: { type: Type.STRING }
      },
      required: ["status", "reasons", "advice", "problematicSections"]
    };

    const chat = ai.chats.create(getModelConfig(apiKey, SYSTEM_INSTRUCTION_AUDIT, schema, settings.model));
    const res = await chat.sendMessage({
      message: [
        ...parts,
        { text: `Qu√° tr√¨nh tr√≠ch xu·∫•t ch·ªâ l·∫•y ƒë∆∞·ª£c ${count} c√¢u h·ªèi. H√£y so s√°nh v·ªõi to√†n b·ªô t√†i li·ªáu v√† b√°o c√°o t·∫°i sao c√≥ s·ª± thi·∫øu h·ª•t n√†y. Ch·ªâ ra ch√≠nh x√°c ch∆∞∆°ng ho·∫∑c trang g·∫∑p kh√≥ khƒÉn n·∫øu c√≥ th·ªÉ.` }
      ]
    });

    return JSON.parse(extractJson(res.text)) as AuditResult;
  });
};
